nohup: ignoring input
cuda
Using downloaded and verified file: ./data/SVHN/extra_32x32.mat
>>> Epoch 0, train: loss 0.3478 acc 0.9109, test: loss 0.1631 acc 0.9552, 
>>> Epoch 1, train: loss 0.1267 acc 0.9652, test: loss 0.1228 acc 0.9656, 
>>> Epoch 2, train: loss 0.0906 acc 0.9756, test: loss 0.1109 acc 0.9685, 
>>> Epoch 3, train: loss 0.0685 acc 0.9826, test: loss 0.1060 acc 0.9706, 
>>> Epoch 4, train: loss 0.0523 acc 0.9877, test: loss 0.1075 acc 0.9701, 
>>> Epoch 5, train: loss 0.0397 acc 0.9914, test: loss 0.1104 acc 0.9706, 
>>> Epoch 6, train: loss 0.0304 acc 0.9941, test: loss 0.1129 acc 0.9710, 
>>> Epoch 7, train: loss 0.0243 acc 0.9953, test: loss 0.1147 acc 0.9706, 
>>> Epoch 8, train: loss 0.0198 acc 0.9962, test: loss 0.1178 acc 0.9704, 
>>> Epoch 9, train: loss 0.0163 acc 0.9968, test: loss 0.1224 acc 0.9703, 
>>> Epoch 10, train: loss 0.0141 acc 0.9972, test: loss 0.1238 acc 0.9709, 
>>> Epoch 11, train: loss 0.0118 acc 0.9977, test: loss 0.1262 acc 0.9702, 
>>> Epoch 12, train: loss 0.0108 acc 0.9978, test: loss 0.1251 acc 0.9711, 
>>> Epoch 13, train: loss 0.0091 acc 0.9981, test: loss 0.1303 acc 0.9708, 
>>> Epoch 14, train: loss 0.0080 acc 0.9983, test: loss 0.1309 acc 0.9717, 
>>> Epoch 15, train: loss 0.0073 acc 0.9985, test: loss 0.1316 acc 0.9716, 
>>> Epoch 16, train: loss 0.0068 acc 0.9985, test: loss 0.1344 acc 0.9715, 
>>> Epoch 17, train: loss 0.0058 acc 0.9988, test: loss 0.1360 acc 0.9715, 
>>> Epoch 18, train: loss 0.0056 acc 0.9987, test: loss 0.1368 acc 0.9719, 
>>> Epoch 19, train: loss 0.0048 acc 0.9990, test: loss 0.1366 acc 0.9728, 
>>> Epoch 20, train: loss 0.0053 acc 0.9988, test: loss 0.1376 acc 0.9728, 
>>> Epoch 21, train: loss 0.0042 acc 0.9991, test: loss 0.1409 acc 0.9724, 
>>> Epoch 22, train: loss 0.0039 acc 0.9991, test: loss 0.1434 acc 0.9722, 
>>> Epoch 23, train: loss 0.0043 acc 0.9990, test: loss 0.1384 acc 0.9730, 
>>> Epoch 24, train: loss 0.0036 acc 0.9992, test: loss 0.1435 acc 0.9724, 
>>> Epoch 25, train: loss 0.0034 acc 0.9992, test: loss 0.1433 acc 0.9729, 
>>> Epoch 26, train: loss 0.0033 acc 0.9992, test: loss 0.1439 acc 0.9730, 
>>> Epoch 27, train: loss 0.0036 acc 0.9991, test: loss 0.1465 acc 0.9723, 
>>> Epoch 28, train: loss 0.0024 acc 0.9995, test: loss 0.1465 acc 0.9729, 
>>> Epoch 29, train: loss 0.0036 acc 0.9991, test: loss 0.1523 acc 0.9718, 
>>> Epoch 30, train: loss 0.0019 acc 0.9997, test: loss 0.1499 acc 0.9731, 
>>> Epoch 31, train: loss 0.0033 acc 0.9991, test: loss 0.1519 acc 0.9722, 
>>> Epoch 32, train: loss 0.0023 acc 0.9995, test: loss 0.1532 acc 0.9721, 
>>> Epoch 33, train: loss 0.0024 acc 0.9994, test: loss 0.1500 acc 0.9734, 
>>> Epoch 34, train: loss 0.0022 acc 0.9995, test: loss 0.1510 acc 0.9732, 
>>> Epoch 35, train: loss 0.0023 acc 0.9994, test: loss 0.1520 acc 0.9730, 
>>> Epoch 36, train: loss 0.0022 acc 0.9995, test: loss 0.1559 acc 0.9726, 
>>> Epoch 37, train: loss 0.0020 acc 0.9995, test: loss 0.1523 acc 0.9738, 
>>> Epoch 38, train: loss 0.0018 acc 0.9996, test: loss 0.1560 acc 0.9732, 
>>> Epoch 39, train: loss 0.0018 acc 0.9996, test: loss 0.1606 acc 0.9727, 
>>> Epoch 40, train: loss 0.0022 acc 0.9994, test: loss 0.1568 acc 0.9728, 
>>> Epoch 41, train: loss 0.0017 acc 0.9996, test: loss 0.1550 acc 0.9742, 
>>> Epoch 42, train: loss 0.0021 acc 0.9995, test: loss 0.1608 acc 0.9729, 
>>> Epoch 43, train: loss 0.0014 acc 0.9997, test: loss 0.1613 acc 0.9730, 
>>> Epoch 44, train: loss 0.0023 acc 0.9994, test: loss 0.1582 acc 0.9738, 
>>> Epoch 45, train: loss 0.0010 acc 0.9998, test: loss 0.1628 acc 0.9731, 
>>> Epoch 46, train: loss 0.0021 acc 0.9995, test: loss 0.1657 acc 0.9724, 
>>> Epoch 47, train: loss 0.0015 acc 0.9996, test: loss 0.1585 acc 0.9742, 
>>> Epoch 48, train: loss 0.0011 acc 0.9998, test: loss 0.1656 acc 0.9733, 
>>> Epoch 49, train: loss 0.0017 acc 0.9996, test: loss 0.1617 acc 0.9741, 
>>> Epoch 50, train: loss 0.0013 acc 0.9997, test: loss 0.1612 acc 0.9740, 
>>> Epoch 51, train: loss 0.0014 acc 0.9997, test: loss 0.1611 acc 0.9738, 
>>> Epoch 52, train: loss 0.0013 acc 0.9997, test: loss 0.1696 acc 0.9735, 
>>> Epoch 53, train: loss 0.0013 acc 0.9997, test: loss 0.1639 acc 0.9735, 
>>> Epoch 54, train: loss 0.0011 acc 0.9998, test: loss 0.1705 acc 0.9726, 
>>> Epoch 55, train: loss 0.0017 acc 0.9996, test: loss 0.1684 acc 0.9736, 
>>> Epoch 56, train: loss 0.0010 acc 0.9998, test: loss 0.1723 acc 0.9734, 
>>> Epoch 57, train: loss 0.0011 acc 0.9998, test: loss 0.1758 acc 0.9735, 
>>> Epoch 58, train: loss 0.0009 acc 0.9998, test: loss 0.1748 acc 0.9731, 
>>> Epoch 59, train: loss 0.0015 acc 0.9996, test: loss 0.1749 acc 0.9727, 
>>> Epoch 60, train: loss 0.0008 acc 0.9998, test: loss 0.1775 acc 0.9725, 
>>> Epoch 61, train: loss 0.0015 acc 0.9996, test: loss 0.1737 acc 0.9736, 
>>> Epoch 62, train: loss 0.0008 acc 0.9998, test: loss 0.1747 acc 0.9733, 
>>> Epoch 63, train: loss 0.0013 acc 0.9997, test: loss 0.1751 acc 0.9729, 
>>> Epoch 64, train: loss 0.0006 acc 0.9999, test: loss 0.1764 acc 0.9735, 
>>> Epoch 65, train: loss 0.0013 acc 0.9996, test: loss 0.1813 acc 0.9734, 
>>> Epoch 66, train: loss 0.0008 acc 0.9998, test: loss 0.1745 acc 0.9738, 
>>> Epoch 67, train: loss 0.0011 acc 0.9997, test: loss 0.1793 acc 0.9737, 
>>> Epoch 68, train: loss 0.0008 acc 0.9998, test: loss 0.1809 acc 0.9734, 
>>> Epoch 69, train: loss 0.0010 acc 0.9998, test: loss 0.1778 acc 0.9737, 
>>> Epoch 70, train: loss 0.0008 acc 0.9998, test: loss 0.1939 acc 0.9714, 
>>> Epoch 71, train: loss 0.0012 acc 0.9997, test: loss 0.1793 acc 0.9735, 
>>> Epoch 72, train: loss 0.0005 acc 0.9999, test: loss 0.1792 acc 0.9739, 
>>> Epoch 73, train: loss 0.0015 acc 0.9996, test: loss 0.1797 acc 0.9728, 
>>> Epoch 74, train: loss 0.0009 acc 0.9998, test: loss 0.1760 acc 0.9735, 
>>> Epoch 75, train: loss 0.0005 acc 0.9999, test: loss 0.1750 acc 0.9743, 
>>> Epoch 76, train: loss 0.0014 acc 0.9996, test: loss 0.1782 acc 0.9739, 
>>> Epoch 77, train: loss 0.0006 acc 0.9999, test: loss 0.1786 acc 0.9741, 
>>> Epoch 78, train: loss 0.0011 acc 0.9997, test: loss 0.1813 acc 0.9732, 
>>> Epoch 79, train: loss 0.0007 acc 0.9998, test: loss 0.1808 acc 0.9734, 
>>> Epoch 80, train: loss 0.0006 acc 0.9999, test: loss 0.1847 acc 0.9731, 
>>> Epoch 81, train: loss 0.0012 acc 0.9997, test: loss 0.1815 acc 0.9737, 
>>> Epoch 82, train: loss 0.0006 acc 0.9999, test: loss 0.1809 acc 0.9742, 
>>> Epoch 83, train: loss 0.0007 acc 0.9998, test: loss 0.1854 acc 0.9733, 
>>> Epoch 84, train: loss 0.0009 acc 0.9998, test: loss 0.1786 acc 0.9747, 
>>> Epoch 85, train: loss 0.0006 acc 0.9999, test: loss 0.1886 acc 0.9729, 
>>> Epoch 86, train: loss 0.0012 acc 0.9997, test: loss 0.1814 acc 0.9739, 
>>> Epoch 87, train: loss 0.0002 acc 1.0000, test: loss 0.1770 acc 0.9750, 
>>> Epoch 88, train: loss 0.0014 acc 0.9996, test: loss 0.1868 acc 0.9729, 
>>> Epoch 89, train: loss 0.0009 acc 0.9998, test: loss 0.1784 acc 0.9744, 
>>> Epoch 90, train: loss 0.0002 acc 1.0000, test: loss 0.1798 acc 0.9753, 
>>> Epoch 91, train: loss 0.0001 acc 1.0000, test: loss 0.1792 acc 0.9759, 
>>> Epoch 92, train: loss 0.0000 acc 1.0000, test: loss 0.1808 acc 0.9760, 
>>> Epoch 93, train: loss 0.0000 acc 1.0000, test: loss 0.1832 acc 0.9760, 
>>> Epoch 94, train: loss 0.0000 acc 1.0000, test: loss 0.1862 acc 0.9758, 
>>> Epoch 95, train: loss 0.0000 acc 1.0000, test: loss 0.1897 acc 0.9761, 
>>> Epoch 96, train: loss 0.0000 acc 1.0000, test: loss 0.1939 acc 0.9758, 
>>> Epoch 97, train: loss 0.0019 acc 0.9994, test: loss 0.1961 acc 0.9738, 
>>> Epoch 98, train: loss 0.0007 acc 0.9998, test: loss 0.1955 acc 0.9742, 
>>> Epoch 99, train: loss 0.0005 acc 0.9999, test: loss 0.2065 acc 0.9734, 
>>> Epoch 100, train: loss 0.0008 acc 0.9998, test: loss 0.1991 acc 0.9738, 
>>> Epoch 101, train: loss 0.0006 acc 0.9998, test: loss 0.1959 acc 0.9739, 
>>> Epoch 102, train: loss 0.0007 acc 0.9998, test: loss 0.1947 acc 0.9742, 
>>> Epoch 103, train: loss 0.0008 acc 0.9998, test: loss 0.1919 acc 0.9746, 
>>> Epoch 104, train: loss 0.0006 acc 0.9998, test: loss 0.1961 acc 0.9741, 
>>> Epoch 105, train: loss 0.0006 acc 0.9998, test: loss 0.1964 acc 0.9736, 
>>> Epoch 106, train: loss 0.0007 acc 0.9998, test: loss 0.2012 acc 0.9732, 
>>> Epoch 107, train: loss 0.0005 acc 0.9999, test: loss 0.2001 acc 0.9735, 
>>> Epoch 108, train: loss 0.0005 acc 0.9999, test: loss 0.2009 acc 0.9739, 
>>> Epoch 109, train: loss 0.0008 acc 0.9998, test: loss 0.2013 acc 0.9736, 
>>> Epoch 110, train: loss 0.0006 acc 0.9998, test: loss 0.1959 acc 0.9738, 
>>> Epoch 111, train: loss 0.0006 acc 0.9999, test: loss 0.2016 acc 0.9736, 
>>> Epoch 112, train: loss 0.0004 acc 0.9999, test: loss 0.1991 acc 0.9737, 
>>> Epoch 113, train: loss 0.0007 acc 0.9998, test: loss 0.2040 acc 0.9730, 
>>> Epoch 114, train: loss 0.0007 acc 0.9998, test: loss 0.1972 acc 0.9740, 
>>> Epoch 115, train: loss 0.0001 acc 1.0000, test: loss 0.1933 acc 0.9746, 
>>> Epoch 116, train: loss 0.0000 acc 1.0000, test: loss 0.1926 acc 0.9749, 
>>> Epoch 117, train: loss 0.0000 acc 1.0000, test: loss 0.1937 acc 0.9751, 
>>> Epoch 118, train: loss 0.0000 acc 1.0000, test: loss 0.1956 acc 0.9754, 
>>> Epoch 119, train: loss 0.0000 acc 1.0000, test: loss 0.1981 acc 0.9755, 
>>> Epoch 120, train: loss 0.0000 acc 1.0000, test: loss 0.2013 acc 0.9757, 
>>> Epoch 121, train: loss 0.0000 acc 1.0000, test: loss 0.2052 acc 0.9760, 
>>> Epoch 122, train: loss 0.0000 acc 1.0000, test: loss 0.2092 acc 0.9761, 
>>> Epoch 123, train: loss 0.0000 acc 1.0000, test: loss 0.2131 acc 0.9763, 
>>> Epoch 124, train: loss 0.0012 acc 0.9997, test: loss 0.2261 acc 0.9729, 
>>> Epoch 125, train: loss 0.0007 acc 0.9998, test: loss 0.2187 acc 0.9735, 
>>> Epoch 126, train: loss 0.0002 acc 0.9999, test: loss 0.2189 acc 0.9744, 
>>> Epoch 127, train: loss 0.0007 acc 0.9998, test: loss 0.2199 acc 0.9735, 
>>> Epoch 128, train: loss 0.0007 acc 0.9998, test: loss 0.2211 acc 0.9736, 
>>> Epoch 129, train: loss 0.0006 acc 0.9998, test: loss 0.2165 acc 0.9740, 
>>> Epoch 130, train: loss 0.0005 acc 0.9998, test: loss 0.2201 acc 0.9738, 
>>> Epoch 131, train: loss 0.0005 acc 0.9999, test: loss 0.2177 acc 0.9738, 
>>> Epoch 132, train: loss 0.0005 acc 0.9999, test: loss 0.2223 acc 0.9732, 
>>> Epoch 133, train: loss 0.0007 acc 0.9998, test: loss 0.2169 acc 0.9739, 
>>> Epoch 134, train: loss 0.0004 acc 0.9999, test: loss 0.2222 acc 0.9726, 
>>> Epoch 135, train: loss 0.0005 acc 0.9998, test: loss 0.2157 acc 0.9735, 
>>> Epoch 136, train: loss 0.0006 acc 0.9999, test: loss 0.2119 acc 0.9740, 
>>> Epoch 137, train: loss 0.0002 acc 1.0000, test: loss 0.2130 acc 0.9741, 
>>> Epoch 138, train: loss 0.0012 acc 0.9996, test: loss 0.2099 acc 0.9733, 
>>> Epoch 139, train: loss 0.0002 acc 1.0000, test: loss 0.2082 acc 0.9751, 
>>> Epoch 140, train: loss 0.0001 acc 1.0000, test: loss 0.2065 acc 0.9753, 
>>> Epoch 141, train: loss 0.0000 acc 1.0000, test: loss 0.2071 acc 0.9755, 
>>> Epoch 142, train: loss 0.0000 acc 1.0000, test: loss 0.2079 acc 0.9756, 
>>> Epoch 143, train: loss 0.0000 acc 1.0000, test: loss 0.2092 acc 0.9760, 
>>> Epoch 144, train: loss 0.0000 acc 1.0000, test: loss 0.2111 acc 0.9761, 
>>> Epoch 145, train: loss 0.0000 acc 1.0000, test: loss 0.2137 acc 0.9763, 
>>> Epoch 146, train: loss 0.0000 acc 1.0000, test: loss 0.2170 acc 0.9763, 
>>> Epoch 147, train: loss 0.0000 acc 1.0000, test: loss 0.2209 acc 0.9763, 
>>> Epoch 148, train: loss 0.0000 acc 1.0000, test: loss 0.2247 acc 0.9764, 
>>> Epoch 149, train: loss 0.0000 acc 1.0000, test: loss 0.2286 acc 0.9763, 
>>> Epoch 150, train: loss 0.0000 acc 1.0000, test: loss 0.2319 acc 0.9764, 
>>> Epoch 151, train: loss 0.0000 acc 1.0000, test: loss 0.2347 acc 0.9764, 
>>> Epoch 152, train: loss 0.0000 acc 1.0000, test: loss 0.2368 acc 0.9763, 
>>> Epoch 153, train: loss 0.0000 acc 1.0000, test: loss 0.2383 acc 0.9763, 
>>> Epoch 154, train: loss 0.0000 acc 1.0000, test: loss 0.2397 acc 0.9762, 
>>> Epoch 155, train: loss 0.0000 acc 1.0000, test: loss 0.2407 acc 0.9763, 
>>> Epoch 156, train: loss 0.0000 acc 1.0000, test: loss 0.2416 acc 0.9763, 
>>> Epoch 157, train: loss 0.0000 acc 1.0000, test: loss 0.2421 acc 0.9763, 
>>> Epoch 158, train: loss 0.0000 acc 1.0000, test: loss 0.2426 acc 0.9764, 
>>> Epoch 159, train: loss 0.0000 acc 1.0000, test: loss 0.2431 acc 0.9762, 
>>> Epoch 160, train: loss 0.0000 acc 1.0000, test: loss 0.2433 acc 0.9762, 
>>> Epoch 161, train: loss 0.0000 acc 1.0000, test: loss 0.2432 acc 0.9762, 
>>> Epoch 162, train: loss 0.0000 acc 1.0000, test: loss 0.2433 acc 0.9763, 
>>> Epoch 163, train: loss 0.0000 acc 1.0000, test: loss 0.2434 acc 0.9763, 
>>> Epoch 164, train: loss 0.0000 acc 1.0000, test: loss 0.2430 acc 0.9763, 
>>> Epoch 165, train: loss 0.0000 acc 1.0000, test: loss 0.2427 acc 0.9763, 
>>> Epoch 166, train: loss 0.0000 acc 1.0000, test: loss 0.2425 acc 0.9764, 
>>> Epoch 167, train: loss 0.0000 acc 1.0000, test: loss 0.2420 acc 0.9763, 
>>> Epoch 168, train: loss 0.0000 acc 1.0000, test: loss 0.2418 acc 0.9763, 
>>> Epoch 169, train: loss 0.0000 acc 1.0000, test: loss 0.2418 acc 0.9763, 
>>> Epoch 170, train: loss 0.0000 acc 1.0000, test: loss 0.2414 acc 0.9764, 
>>> Epoch 171, train: loss 0.0000 acc 1.0000, test: loss 0.2414 acc 0.9764, 
>>> Epoch 172, train: loss 0.0000 acc 1.0000, test: loss 0.2411 acc 0.9764, 
>>> Epoch 173, train: loss 0.0000 acc 1.0000, test: loss 0.2410 acc 0.9763, 
>>> Epoch 174, train: loss 0.0000 acc 1.0000, test: loss 0.2406 acc 0.9763, 
>>> Epoch 175, train: loss 0.0000 acc 1.0000, test: loss 0.2401 acc 0.9763, 
>>> Epoch 176, train: loss 0.0000 acc 1.0000, test: loss 0.2399 acc 0.9762, 
>>> Epoch 177, train: loss 0.0000 acc 1.0000, test: loss 0.2396 acc 0.9762, 
>>> Epoch 178, train: loss 0.0000 acc 1.0000, test: loss 0.2394 acc 0.9762, 
>>> Epoch 179, train: loss 0.0000 acc 1.0000, test: loss 0.2391 acc 0.9762, 
>>> Epoch 180, train: loss 0.0000 acc 1.0000, test: loss 0.2388 acc 0.9763, 
>>> Epoch 181, train: loss 0.0000 acc 1.0000, test: loss 0.2383 acc 0.9763, 
>>> Epoch 182, train: loss 0.0000 acc 1.0000, test: loss 0.2381 acc 0.9763, 
>>> Epoch 183, train: loss 0.0000 acc 1.0000, test: loss 0.2378 acc 0.9763, 
>>> Epoch 184, train: loss 0.0000 acc 1.0000, test: loss 0.2377 acc 0.9763, 
>>> Epoch 185, train: loss 0.0000 acc 1.0000, test: loss 0.2374 acc 0.9763, 
>>> Epoch 186, train: loss 0.0000 acc 1.0000, test: loss 0.2372 acc 0.9763, 
>>> Epoch 187, train: loss 0.0000 acc 1.0000, test: loss 0.2370 acc 0.9764, 
>>> Epoch 188, train: loss 0.0000 acc 1.0000, test: loss 0.2367 acc 0.9764, 
>>> Epoch 189, train: loss 0.0000 acc 1.0000, test: loss 0.2364 acc 0.9764, 
>>> Epoch 190, train: loss 0.0000 acc 1.0000, test: loss 0.2361 acc 0.9763, 
>>> Epoch 191, train: loss 0.0000 acc 1.0000, test: loss 0.2359 acc 0.9764, 
>>> Epoch 192, train: loss 0.0000 acc 1.0000, test: loss 0.2357 acc 0.9765, 
>>> Epoch 193, train: loss 0.0000 acc 1.0000, test: loss 0.2356 acc 0.9764, 
>>> Epoch 194, train: loss 0.0000 acc 1.0000, test: loss 0.2352 acc 0.9764, 
>>> Epoch 195, train: loss 0.0000 acc 1.0000, test: loss 0.2348 acc 0.9764, 
>>> Epoch 196, train: loss 0.0000 acc 1.0000, test: loss 0.2346 acc 0.9766, 
>>> Epoch 197, train: loss 0.0000 acc 1.0000, test: loss 0.2343 acc 0.9765, 
>>> Epoch 198, train: loss 0.0000 acc 1.0000, test: loss 0.2339 acc 0.9765, 
>>> Epoch 199, train: loss 0.0000 acc 1.0000, test: loss 0.2338 acc 0.9766, 
>>> Epoch 200, train: loss 0.0000 acc 1.0000, test: loss 0.2334 acc 0.9764, 
>>> Epoch 201, train: loss 0.0000 acc 1.0000, test: loss 0.2334 acc 0.9765, 
>>> Epoch 202, train: loss 0.0000 acc 1.0000, test: loss 0.2331 acc 0.9764, 
>>> Epoch 203, train: loss 0.0000 acc 1.0000, test: loss 0.2325 acc 0.9764, 
>>> Epoch 204, train: loss 0.0000 acc 1.0000, test: loss 0.2325 acc 0.9764, 
>>> Epoch 205, train: loss 0.0000 acc 1.0000, test: loss 0.2325 acc 0.9763, 
>>> Epoch 206, train: loss 0.0000 acc 1.0000, test: loss 0.2325 acc 0.9764, 
>>> Epoch 207, train: loss 0.0000 acc 1.0000, test: loss 0.2321 acc 0.9764, 
>>> Epoch 208, train: loss 0.0000 acc 1.0000, test: loss 0.2320 acc 0.9764, 
>>> Epoch 209, train: loss 0.0000 acc 1.0000, test: loss 0.2319 acc 0.9763, 
>>> Epoch 210, train: loss 0.0000 acc 1.0000, test: loss 0.2314 acc 0.9765, 
>>> Epoch 211, train: loss 0.0000 acc 1.0000, test: loss 0.2313 acc 0.9765, 
>>> Epoch 212, train: loss 0.0000 acc 1.0000, test: loss 0.2314 acc 0.9764, 
>>> Epoch 213, train: loss 0.0000 acc 1.0000, test: loss 0.2311 acc 0.9764, 
>>> Epoch 214, train: loss 0.0000 acc 1.0000, test: loss 0.2311 acc 0.9765, 
>>> Epoch 215, train: loss 0.0000 acc 1.0000, test: loss 0.2308 acc 0.9765, 
>>> Epoch 216, train: loss 0.0000 acc 1.0000, test: loss 0.2305 acc 0.9765, 
>>> Epoch 217, train: loss 0.0000 acc 1.0000, test: loss 0.2304 acc 0.9764, 
>>> Epoch 218, train: loss 0.0000 acc 1.0000, test: loss 0.2301 acc 0.9764, 
>>> Epoch 219, train: loss 0.0000 acc 1.0000, test: loss 0.2299 acc 0.9765, 
>>> Epoch 220, train: loss 0.0000 acc 1.0000, test: loss 0.2297 acc 0.9764, 
>>> Epoch 221, train: loss 0.0000 acc 1.0000, test: loss 0.2296 acc 0.9764, 
>>> Epoch 222, train: loss 0.0000 acc 1.0000, test: loss 0.2295 acc 0.9764, 
>>> Epoch 223, train: loss 0.0000 acc 1.0000, test: loss 0.2292 acc 0.9764, 
>>> Epoch 224, train: loss 0.0000 acc 1.0000, test: loss 0.2292 acc 0.9763, 
>>> Epoch 225, train: loss 0.0000 acc 1.0000, test: loss 0.2290 acc 0.9765, 
>>> Epoch 226, train: loss 0.0000 acc 1.0000, test: loss 0.2290 acc 0.9763, 
>>> Epoch 227, train: loss 0.0000 acc 1.0000, test: loss 0.2288 acc 0.9764, 
>>> Epoch 228, train: loss 0.0000 acc 1.0000, test: loss 0.2288 acc 0.9763, 
>>> Epoch 229, train: loss 0.0000 acc 1.0000, test: loss 0.2288 acc 0.9763, 
>>> Epoch 230, train: loss 0.0000 acc 1.0000, test: loss 0.2284 acc 0.9764, 
>>> Epoch 231, train: loss 0.0000 acc 1.0000, test: loss 0.2282 acc 0.9763, 
>>> Epoch 232, train: loss 0.0000 acc 1.0000, test: loss 0.2283 acc 0.9764, 
>>> Epoch 233, train: loss 0.0000 acc 1.0000, test: loss 0.2282 acc 0.9764, 
>>> Epoch 234, train: loss 0.0000 acc 1.0000, test: loss 0.2282 acc 0.9764, 
>>> Epoch 235, train: loss 0.0000 acc 1.0000, test: loss 0.2281 acc 0.9763, 
>>> Epoch 236, train: loss 0.0000 acc 1.0000, test: loss 0.2278 acc 0.9763, 
>>> Epoch 237, train: loss 0.0000 acc 1.0000, test: loss 0.2278 acc 0.9764, 
>>> Epoch 238, train: loss 0.0000 acc 1.0000, test: loss 0.2277 acc 0.9762, 
>>> Epoch 239, train: loss 0.0000 acc 1.0000, test: loss 0.2275 acc 0.9764, 
>>> Epoch 240, train: loss 0.0000 acc 1.0000, test: loss 0.2272 acc 0.9764, 
>>> Epoch 241, train: loss 0.0000 acc 1.0000, test: loss 0.2273 acc 0.9766, 
>>> Epoch 242, train: loss 0.0000 acc 1.0000, test: loss 0.2270 acc 0.9764, 
>>> Epoch 243, train: loss 0.0000 acc 1.0000, test: loss 0.2269 acc 0.9764, 
>>> Epoch 244, train: loss 0.0000 acc 1.0000, test: loss 0.2265 acc 0.9764, 
>>> Epoch 245, train: loss 0.0000 acc 1.0000, test: loss 0.2267 acc 0.9764, 
>>> Epoch 246, train: loss 0.0000 acc 1.0000, test: loss 0.2268 acc 0.9764, 
>>> Epoch 247, train: loss 0.0000 acc 1.0000, test: loss 0.2266 acc 0.9765, 
>>> Epoch 248, train: loss 0.0000 acc 1.0000, test: loss 0.2265 acc 0.9763, 
>>> Epoch 249, train: loss 0.0000 acc 1.0000, test: loss 0.2267 acc 0.9764, 
>>> Epoch 250, train: loss 0.0000 acc 1.0000, test: loss 0.2266 acc 0.9764, 
>>> Epoch 251, train: loss 0.0000 acc 1.0000, test: loss 0.2264 acc 0.9766, 
>>> Epoch 252, train: loss 0.0000 acc 1.0000, test: loss 0.2265 acc 0.9765, 
>>> Epoch 253, train: loss 0.0000 acc 1.0000, test: loss 0.2264 acc 0.9765, 
>>> Epoch 254, train: loss 0.0000 acc 1.0000, test: loss 0.2264 acc 0.9764, 
>>> Epoch 255, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9764, 
>>> Epoch 256, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9764, 
>>> Epoch 257, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9764, 
>>> Epoch 258, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9764, 
>>> Epoch 259, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9765, 
>>> Epoch 260, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9765, 
>>> Epoch 261, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9763, 
>>> Epoch 262, train: loss 0.0000 acc 1.0000, test: loss 0.2260 acc 0.9765, 
>>> Epoch 263, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9764, 
>>> Epoch 264, train: loss 0.0000 acc 1.0000, test: loss 0.2260 acc 0.9764, 
>>> Epoch 265, train: loss 0.0000 acc 1.0000, test: loss 0.2258 acc 0.9764, 
>>> Epoch 266, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9762, 
>>> Epoch 267, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9762, 
>>> Epoch 268, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9762, 
>>> Epoch 269, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9762, 
>>> Epoch 270, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9762, 
>>> Epoch 271, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9762, 
>>> Epoch 272, train: loss 0.0000 acc 1.0000, test: loss 0.2259 acc 0.9764, 
>>> Epoch 273, train: loss 0.0000 acc 1.0000, test: loss 0.2259 acc 0.9762, 
>>> Epoch 274, train: loss 0.0000 acc 1.0000, test: loss 0.2258 acc 0.9763, 
>>> Epoch 275, train: loss 0.0000 acc 1.0000, test: loss 0.2258 acc 0.9762, 
>>> Epoch 276, train: loss 0.0000 acc 1.0000, test: loss 0.2259 acc 0.9762, 
>>> Epoch 277, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9762, 
>>> Epoch 278, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9761, 
>>> Epoch 279, train: loss 0.0000 acc 1.0000, test: loss 0.2264 acc 0.9760, 
>>> Epoch 280, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9762, 
>>> Epoch 281, train: loss 0.0000 acc 1.0000, test: loss 0.2265 acc 0.9761, 
>>> Epoch 282, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9761, 
>>> Epoch 283, train: loss 0.0000 acc 1.0000, test: loss 0.2265 acc 0.9761, 
>>> Epoch 284, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9763, 
>>> Epoch 285, train: loss 0.0000 acc 1.0000, test: loss 0.2261 acc 0.9763, 
>>> Epoch 286, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9762, 
>>> Epoch 287, train: loss 0.0000 acc 1.0000, test: loss 0.2262 acc 0.9762, 
>>> Epoch 288, train: loss 0.0000 acc 1.0000, test: loss 0.2263 acc 0.9762, 
>>> Epoch 289, train: loss 0.0000 acc 1.0000, test: loss 0.2267 acc 0.9762, 
>>> Epoch 290, train: loss 0.0000 acc 1.0000, test: loss 0.2267 acc 0.9763, 
>>> Epoch 291, train: loss 0.0000 acc 1.0000, test: loss 0.2267 acc 0.9760, 
Test accuracy has not improved in 51 epochs, stop train
Best model test accuracy: 0.9765970706939697, train accuracy: 1.0
>>> model saved to ./models/f_net
QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-eladb3'
